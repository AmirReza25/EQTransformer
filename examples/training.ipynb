{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (IV) Model Building\n",
    "You can also train the neural network on your data and build and test your own model using the following modules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Training:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can build your own EQTransformer with varying encoder sizes and train it using your own data. Your data should be in the same format as our sample data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-25 13:21:41.304808: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, 6000, 3)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 6000, 8)      272         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 3000, 8)      0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 3000, 16)     1168        max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 1500, 16)     0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 1500, 16)     1808        max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 750, 16)      0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 750, 32)      3616        max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 375, 32)      0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 375, 32)      5152        max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 188, 32)      0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 188, 64)      10304       max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 94, 64)       0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 94, 64)       12352       max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 47, 64)       0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 47, 64)       256         max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 47, 64)       0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d (SpatialDropo (None, 47, 64)       0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 47, 64)       12352       spatial_dropout1d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 47, 64)       256         conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 47, 64)       0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 47, 64)       0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 47, 64)       12352       spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 47, 64)       0           max_pooling1d_6[0][0]            \n",
      "                                                                 conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 47, 64)       256         add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 47, 64)       0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_2 (SpatialDro (None, 47, 64)       0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 47, 64)       12352       spatial_dropout1d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 47, 64)       256         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 47, 64)       0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_3 (SpatialDro (None, 47, 64)       0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 47, 64)       12352       spatial_dropout1d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 47, 64)       0           add[0][0]                        \n",
      "                                                                 conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 47, 32)       10368       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 47, 16)       528         bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 47, 16)       64          conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attentionD0 (SeqSelfAttention)  [(None, 47, 16), (No 1089        batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 47, 16)       0           batch_normalization_4[0][0]      \n",
      "                                                                 attentionD0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization (LayerNorma (None, 47, 16)       32          add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "feed_forward (FeedForward)      (None, 47, 16)       4240        layer_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 47, 16)       0           layer_normalization[0][0]        \n",
      "                                                                 feed_forward[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_1 (LayerNor (None, 47, 16)       32          add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "attentionD (SeqSelfAttention)   [(None, 47, 16), (No 1089        layer_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 47, 16)       0           layer_normalization_1[0][0]      \n",
      "                                                                 attentionD[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_2 (LayerNor (None, 47, 16)       32          add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "feed_forward_1 (FeedForward)    (None, 47, 16)       4240        layer_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 47, 16)       0           layer_normalization_2[0][0]      \n",
      "                                                                 feed_forward_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_3 (LayerNor (None, 47, 16)       32          add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 47, 16)       2112        layer_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 47, 16)       2112        layer_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "attentionP (SeqSelfAttention)   [(None, 47, 16), (No 1089        lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "attentionS (SeqSelfAttention)   [(None, 47, 16), (No 1089        lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d (UpSampling1D)    (None, 94, 16)       0           layer_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_7 (UpSampling1D)  (None, 94, 16)       0           attentionP[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_14 (UpSampling1D) (None, 94, 16)       0           attentionS[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 94, 64)       3136        up_sampling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 94, 64)       3136        up_sampling1d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, 94, 64)       3136        up_sampling1d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_1 (UpSampling1D)  (None, 188, 64)      0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_8 (UpSampling1D)  (None, 188, 64)      0           conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_15 (UpSampling1D) (None, 188, 64)      0           conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 188, 64)      20544       up_sampling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 188, 64)      20544       up_sampling1d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 188, 64)      20544       up_sampling1d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_2 (UpSampling1D)  (None, 376, 64)      0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_9 (UpSampling1D)  (None, 376, 64)      0           conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_16 (UpSampling1D) (None, 376, 64)      0           conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 376, 32)      10272       up_sampling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 376, 32)      10272       up_sampling1d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, 376, 32)      10272       up_sampling1d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_3 (UpSampling1D)  (None, 752, 32)      0           conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_10 (UpSampling1D) (None, 752, 32)      0           conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_17 (UpSampling1D) (None, 752, 32)      0           conv1d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cropping1d (Cropping1D)         (None, 750, 32)      0           up_sampling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "cropping1d_1 (Cropping1D)       (None, 750, 32)      0           up_sampling1d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "cropping1d_2 (Cropping1D)       (None, 750, 32)      0           up_sampling1d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 750, 32)      7200        cropping1d[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 750, 32)      7200        cropping1d_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)              (None, 750, 32)      7200        cropping1d_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_4 (UpSampling1D)  (None, 1500, 32)     0           conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_11 (UpSampling1D) (None, 1500, 32)     0           conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_18 (UpSampling1D) (None, 1500, 32)     0           conv1d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 1500, 16)     3600        up_sampling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 1500, 16)     3600        up_sampling1d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, 1500, 16)     3600        up_sampling1d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_5 (UpSampling1D)  (None, 3000, 16)     0           conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_12 (UpSampling1D) (None, 3000, 16)     0           conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_19 (UpSampling1D) (None, 3000, 16)     0           conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 3000, 16)     2320        up_sampling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 3000, 16)     2320        up_sampling1d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_31 (Conv1D)              (None, 3000, 16)     2320        up_sampling1d_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_6 (UpSampling1D)  (None, 6000, 16)     0           conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_13 (UpSampling1D) (None, 6000, 16)     0           conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_20 (UpSampling1D) (None, 6000, 16)     0           conv1d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 6000, 8)      1416        up_sampling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 6000, 8)      1416        up_sampling1d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, 6000, 8)      1416        up_sampling1d_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "detector (Conv1D)               (None, 6000, 1)      89          conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "picker_P (Conv1D)               (None, 6000, 1)      89          conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "picker_S (Conv1D)               (None, 6000, 1)      89          conv1d_32[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 258,983\n",
      "Trainable params: 258,439\n",
      "Non-trainable params: 544\n",
      "__________________________________________________________________________________________________\n",
      "Started training in generator mode ...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "`class_weight` is only supported for Models with a single output.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/amirreza/Desktop/Desktop/Project/Final Project/EQTransformer/examples/training.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/amirreza/Desktop/Desktop/Project/Final%20Project/EQTransformer/examples/training.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mEQTransformer\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtrainer\u001b[39;00m \u001b[39mimport\u001b[39;00m trainer\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/amirreza/Desktop/Desktop/Project/Final%20Project/EQTransformer/examples/training.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m trainer(input_hdf5\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m../ModelsAndSampleData/100samples.hdf5\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/amirreza/Desktop/Desktop/Project/Final%20Project/EQTransformer/examples/training.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m         input_csv\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m../ModelsAndSampleData/100samples.csv\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/amirreza/Desktop/Desktop/Project/Final%20Project/EQTransformer/examples/training.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         output_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtest_trainer\u001b[39;49m\u001b[39m'\u001b[39;49m,                \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/amirreza/Desktop/Desktop/Project/Final%20Project/EQTransformer/examples/training.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         cnn_blocks\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/amirreza/Desktop/Desktop/Project/Final%20Project/EQTransformer/examples/training.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         lstm_blocks\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/amirreza/Desktop/Desktop/Project/Final%20Project/EQTransformer/examples/training.ipynb#W3sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         padding\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msame\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/amirreza/Desktop/Desktop/Project/Final%20Project/EQTransformer/examples/training.ipynb#W3sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/amirreza/Desktop/Desktop/Project/Final%20Project/EQTransformer/examples/training.ipynb#W3sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         drop_rate\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/amirreza/Desktop/Desktop/Project/Final%20Project/EQTransformer/examples/training.ipynb#W3sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         label_type\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mgaussian\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/amirreza/Desktop/Desktop/Project/Final%20Project/EQTransformer/examples/training.ipynb#W3sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         add_event_r\u001b[39m=\u001b[39;49m\u001b[39m0.6\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/amirreza/Desktop/Desktop/Project/Final%20Project/EQTransformer/examples/training.ipynb#W3sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m         add_gap_r\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/amirreza/Desktop/Desktop/Project/Final%20Project/EQTransformer/examples/training.ipynb#W3sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m         shift_event_r\u001b[39m=\u001b[39;49m\u001b[39m0.9\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/amirreza/Desktop/Desktop/Project/Final%20Project/EQTransformer/examples/training.ipynb#W3sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m         add_noise_r\u001b[39m=\u001b[39;49m\u001b[39m0.5\u001b[39;49m, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/amirreza/Desktop/Desktop/Project/Final%20Project/EQTransformer/examples/training.ipynb#W3sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m         mode\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mgenerator\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/amirreza/Desktop/Desktop/Project/Final%20Project/EQTransformer/examples/training.ipynb#W3sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m         train_valid_test_split\u001b[39m=\u001b[39;49m[\u001b[39m0.60\u001b[39;49m, \u001b[39m0.20\u001b[39;49m, \u001b[39m0.20\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/amirreza/Desktop/Desktop/Project/Final%20Project/EQTransformer/examples/training.ipynb#W3sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m         batch_size\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/amirreza/Desktop/Desktop/Project/Final%20Project/EQTransformer/examples/training.ipynb#W3sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m         epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/amirreza/Desktop/Desktop/Project/Final%20Project/EQTransformer/examples/training.ipynb#W3sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m         patience\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/amirreza/Desktop/Desktop/Project/Final%20Project/EQTransformer/examples/training.ipynb#W3sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m         gpuid\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/amirreza/Desktop/Desktop/Project/Final%20Project/EQTransformer/examples/training.ipynb#W3sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m         gpu_limit\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/EQTransformer-0.1.61-py3.9.egg/EQTransformer/core/trainer.py:355\u001b[0m, in \u001b[0;36mtrainer\u001b[0;34m(input_hdf5, input_csv, output_name, input_dimention, cnn_blocks, lstm_blocks, padding, activation, drop_rate, shuffle, label_type, normalization_mode, augmentation, add_event_r, shift_event_r, add_noise_r, drop_channel_r, add_gap_r, coda_ratio, scale_amplitude_r, pre_emphasis, loss_weights, loss_types, train_valid_test_split, mode, batch_size, epochs, monitor, patience, gpuid, gpu_limit, use_multiprocessing)\u001b[0m\n\u001b[1;32m    351\u001b[0m     end_training \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()  \n\u001b[1;32m    353\u001b[0m     \u001b[39mreturn\u001b[39;00m history, model, start_training, end_training, save_dir, save_models, \u001b[39mlen\u001b[39m(training), \u001b[39mlen\u001b[39m(validation)\n\u001b[0;32m--> 355\u001b[0m history, model, start_training, end_training, save_dir, save_models, training_size, validation_size\u001b[39m=\u001b[39mtrain(args)  \n\u001b[1;32m    356\u001b[0m _document_training(history, model, start_training, end_training, save_dir, save_models, training_size, validation_size, args)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/EQTransformer-0.1.61-py3.9.egg/EQTransformer/core/trainer.py:317\u001b[0m, in \u001b[0;36mtrainer.<locals>.train\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    314\u001b[0m     validation_generator \u001b[39m=\u001b[39m DataGenerator(validation, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams_validation) \n\u001b[1;32m    316\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mStarted training in generator mode ...\u001b[39m\u001b[39m'\u001b[39m) \n\u001b[0;32m--> 317\u001b[0m     history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit_generator(generator\u001b[39m=\u001b[39;49mtraining_generator,\n\u001b[1;32m    318\u001b[0m                                   validation_data\u001b[39m=\u001b[39;49mvalidation_generator,\n\u001b[1;32m    319\u001b[0m                                   use_multiprocessing\u001b[39m=\u001b[39;49margs[\u001b[39m'\u001b[39;49m\u001b[39muse_multiprocessing\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    320\u001b[0m                                   workers\u001b[39m=\u001b[39;49mmultiprocessing\u001b[39m.\u001b[39;49mcpu_count(),    \n\u001b[1;32m    321\u001b[0m                                   callbacks\u001b[39m=\u001b[39;49mcallbacks, \n\u001b[1;32m    322\u001b[0m                                   epochs\u001b[39m=\u001b[39;49margs[\u001b[39m'\u001b[39;49m\u001b[39mepochs\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    323\u001b[0m                                   class_weight\u001b[39m=\u001b[39;49m{\u001b[39m0\u001b[39;49m: \u001b[39m0.11\u001b[39;49m, \u001b[39m1\u001b[39;49m: \u001b[39m0.89\u001b[39;49m})\n\u001b[1;32m    325\u001b[0m \u001b[39melif\u001b[39;00m args[\u001b[39m'\u001b[39m\u001b[39mmode\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mpreload\u001b[39m\u001b[39m'\u001b[39m: \n\u001b[1;32m    326\u001b[0m     X, y1, y2, y3 \u001b[39m=\u001b[39m data_reader(list_IDs\u001b[39m=\u001b[39mtraining\u001b[39m+\u001b[39mvalidation, \n\u001b[1;32m    327\u001b[0m                                file_name\u001b[39m=\u001b[39m\u001b[39mstr\u001b[39m(args[\u001b[39m'\u001b[39m\u001b[39minput_hdf5\u001b[39m\u001b[39m'\u001b[39m]), \n\u001b[1;32m    328\u001b[0m                                dim\u001b[39m=\u001b[39margs[\u001b[39m'\u001b[39m\u001b[39minput_dimention\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m], \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    338\u001b[0m                                scale_amplitude_r\u001b[39m=\u001b[39margs[\u001b[39m'\u001b[39m\u001b[39mscale_amplitude_r\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m    339\u001b[0m                                pre_emphasis\u001b[39m=\u001b[39margs[\u001b[39m'\u001b[39m\u001b[39mpre_emphasis\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1943\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1934\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[1;32m   1935\u001b[0m \n\u001b[1;32m   1936\u001b[0m \u001b[39mDEPRECATED:\u001b[39;00m\n\u001b[1;32m   1937\u001b[0m \u001b[39m  `Model.fit` now supports generators, so there is no longer any need to use\u001b[39;00m\n\u001b[1;32m   1938\u001b[0m \u001b[39m  this endpoint.\u001b[39;00m\n\u001b[1;32m   1939\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1940\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\u001b[39m'\u001b[39m\u001b[39m`Model.fit_generator` is deprecated and \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1941\u001b[0m               \u001b[39m'\u001b[39m\u001b[39mwill be removed in a future version. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1942\u001b[0m               \u001b[39m'\u001b[39m\u001b[39mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> 1943\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m   1944\u001b[0m     generator,\n\u001b[1;32m   1945\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[1;32m   1946\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m   1947\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   1948\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   1949\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_data,\n\u001b[1;32m   1950\u001b[0m     validation_steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[1;32m   1951\u001b[0m     validation_freq\u001b[39m=\u001b[39;49mvalidation_freq,\n\u001b[1;32m   1952\u001b[0m     class_weight\u001b[39m=\u001b[39;49mclass_weight,\n\u001b[1;32m   1953\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   1954\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   1955\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   1956\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[1;32m   1957\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49minitial_epoch)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1133\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1127\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cluster_coordinator \u001b[39m=\u001b[39m cluster_coordinator\u001b[39m.\u001b[39mClusterCoordinator(\n\u001b[1;32m   1128\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy)\n\u001b[1;32m   1130\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy\u001b[39m.\u001b[39mscope(), \\\n\u001b[1;32m   1131\u001b[0m      training_utils\u001b[39m.\u001b[39mRespectCompiledTrainableState(\u001b[39mself\u001b[39m):\n\u001b[1;32m   1132\u001b[0m   \u001b[39m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[39;00m\n\u001b[0;32m-> 1133\u001b[0m   data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39;49mget_data_handler(\n\u001b[1;32m   1134\u001b[0m       x\u001b[39m=\u001b[39;49mx,\n\u001b[1;32m   1135\u001b[0m       y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m   1136\u001b[0m       sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1137\u001b[0m       batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m   1138\u001b[0m       steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[1;32m   1139\u001b[0m       initial_epoch\u001b[39m=\u001b[39;49minitial_epoch,\n\u001b[1;32m   1140\u001b[0m       epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m   1141\u001b[0m       shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[1;32m   1142\u001b[0m       class_weight\u001b[39m=\u001b[39;49mclass_weight,\n\u001b[1;32m   1143\u001b[0m       max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   1144\u001b[0m       workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   1145\u001b[0m       use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   1146\u001b[0m       model\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1147\u001b[0m       steps_per_execution\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_steps_per_execution)\n\u001b[1;32m   1149\u001b[0m   \u001b[39m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[1;32m   1150\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(callbacks, callbacks_module\u001b[39m.\u001b[39mCallbackList):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/keras/engine/data_adapter.py:1364\u001b[0m, in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1362\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(kwargs[\u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39m_cluster_coordinator\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   1363\u001b[0m   \u001b[39mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m-> 1364\u001b[0m \u001b[39mreturn\u001b[39;00m DataHandler(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/keras/engine/data_adapter.py:1174\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1171\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_step_increment \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution_value \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1172\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_insufficient_data \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1174\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_configure_dataset_and_inferred_steps(strategy, x, steps_per_epoch,\n\u001b[1;32m   1175\u001b[0m                                            class_weight, distribute)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/keras/engine/data_adapter.py:1186\u001b[0m, in \u001b[0;36mDataHandler._configure_dataset_and_inferred_steps\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1184\u001b[0m dataset \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_adapter\u001b[39m.\u001b[39mget_dataset()\n\u001b[1;32m   1185\u001b[0m \u001b[39mif\u001b[39;00m class_weight:\n\u001b[0;32m-> 1186\u001b[0m   dataset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39;49mmap(_make_class_weight_map_fn(class_weight))\n\u001b[1;32m   1187\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inferred_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_infer_steps(steps_per_epoch, dataset)\n\u001b[1;32m   1189\u001b[0m \u001b[39m# `PreprocessingLayer.adapt` does not currently support distributed\u001b[39;00m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# datasets, so we pass `distribute=False` there.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:1925\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[0;34m(self, map_func, num_parallel_calls, deterministic)\u001b[0m\n\u001b[1;32m   1922\u001b[0m   \u001b[39mif\u001b[39;00m deterministic \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m DEBUG_MODE:\n\u001b[1;32m   1923\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mThe `deterministic` argument has no effect unless the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1924\u001b[0m                   \u001b[39m\"\u001b[39m\u001b[39m`num_parallel_calls` argument is specified.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1925\u001b[0m   \u001b[39mreturn\u001b[39;00m MapDataset(\u001b[39mself\u001b[39;49m, map_func, preserve_cardinality\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m   1926\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1927\u001b[0m   \u001b[39mreturn\u001b[39;00m ParallelMapDataset(\n\u001b[1;32m   1928\u001b[0m       \u001b[39mself\u001b[39m,\n\u001b[1;32m   1929\u001b[0m       map_func,\n\u001b[1;32m   1930\u001b[0m       num_parallel_calls,\n\u001b[1;32m   1931\u001b[0m       deterministic,\n\u001b[1;32m   1932\u001b[0m       preserve_cardinality\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:4483\u001b[0m, in \u001b[0;36mMapDataset.__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   4481\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_use_inter_op_parallelism \u001b[39m=\u001b[39m use_inter_op_parallelism\n\u001b[1;32m   4482\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_preserve_cardinality \u001b[39m=\u001b[39m preserve_cardinality\n\u001b[0;32m-> 4483\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func \u001b[39m=\u001b[39m StructuredFunctionWrapper(\n\u001b[1;32m   4484\u001b[0m     map_func,\n\u001b[1;32m   4485\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transformation_name(),\n\u001b[1;32m   4486\u001b[0m     dataset\u001b[39m=\u001b[39;49minput_dataset,\n\u001b[1;32m   4487\u001b[0m     use_legacy_function\u001b[39m=\u001b[39;49muse_legacy_function)\n\u001b[1;32m   4488\u001b[0m variant_tensor \u001b[39m=\u001b[39m gen_dataset_ops\u001b[39m.\u001b[39mmap_dataset(\n\u001b[1;32m   4489\u001b[0m     input_dataset\u001b[39m.\u001b[39m_variant_tensor,  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   4490\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func\u001b[39m.\u001b[39mfunction\u001b[39m.\u001b[39mcaptured_inputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4493\u001b[0m     preserve_cardinality\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_preserve_cardinality,\n\u001b[1;32m   4494\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_structure)\n\u001b[1;32m   4495\u001b[0m \u001b[39msuper\u001b[39m(MapDataset, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(input_dataset, variant_tensor)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:3712\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   3710\u001b[0m resource_tracker \u001b[39m=\u001b[39m tracking\u001b[39m.\u001b[39mResourceTracker()\n\u001b[1;32m   3711\u001b[0m \u001b[39mwith\u001b[39;00m tracking\u001b[39m.\u001b[39mresource_tracker_scope(resource_tracker):\n\u001b[0;32m-> 3712\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function \u001b[39m=\u001b[39m fn_factory()\n\u001b[1;32m   3713\u001b[0m   \u001b[39m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[1;32m   3714\u001b[0m   add_to_graph \u001b[39m&\u001b[39m\u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3134\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3125\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_concrete_function\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   3126\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001b[39;00m\n\u001b[1;32m   3127\u001b[0m \n\u001b[1;32m   3128\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3132\u001b[0m \u001b[39m       or `tf.Tensor` or `tf.TensorSpec`.\u001b[39;00m\n\u001b[1;32m   3133\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3134\u001b[0m   graph_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_concrete_function_garbage_collected(\n\u001b[1;32m   3135\u001b[0m       \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   3136\u001b[0m   graph_function\u001b[39m.\u001b[39m_garbage_collector\u001b[39m.\u001b[39mrelease()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   3137\u001b[0m   \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3100\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3098\u001b[0m   args, kwargs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   3099\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m-> 3100\u001b[0m   graph_function, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n\u001b[1;32m   3101\u001b[0m   seen_names \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[1;32m   3102\u001b[0m   captured \u001b[39m=\u001b[39m object_identity\u001b[39m.\u001b[39mObjectIdentitySet(\n\u001b[1;32m   3103\u001b[0m       graph_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39minternal_captures)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3444\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3440\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_define_function_with_shape_relaxation(\n\u001b[1;32m   3441\u001b[0m       args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[1;32m   3443\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_cache\u001b[39m.\u001b[39mmissed\u001b[39m.\u001b[39madd(call_context_key)\n\u001b[0;32m-> 3444\u001b[0m graph_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_graph_function(args, kwargs)\n\u001b[1;32m   3445\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_cache\u001b[39m.\u001b[39mprimary[cache_key] \u001b[39m=\u001b[39m graph_function\n\u001b[1;32m   3447\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3279\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3274\u001b[0m missing_arg_names \u001b[39m=\u001b[39m [\n\u001b[1;32m   3275\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (arg, i) \u001b[39mfor\u001b[39;00m i, arg \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(missing_arg_names)\n\u001b[1;32m   3276\u001b[0m ]\n\u001b[1;32m   3277\u001b[0m arg_names \u001b[39m=\u001b[39m base_arg_names \u001b[39m+\u001b[39m missing_arg_names\n\u001b[1;32m   3278\u001b[0m graph_function \u001b[39m=\u001b[39m ConcreteFunction(\n\u001b[0;32m-> 3279\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[1;32m   3280\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[1;32m   3281\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[1;32m   3282\u001b[0m         args,\n\u001b[1;32m   3283\u001b[0m         kwargs,\n\u001b[1;32m   3284\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_signature,\n\u001b[1;32m   3285\u001b[0m         autograph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph,\n\u001b[1;32m   3286\u001b[0m         autograph_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph_options,\n\u001b[1;32m   3287\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[1;32m   3288\u001b[0m         override_flat_arg_shapes\u001b[39m=\u001b[39;49moverride_flat_arg_shapes,\n\u001b[1;32m   3289\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value),\n\u001b[1;32m   3290\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[1;32m   3291\u001b[0m     function_spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[1;32m   3292\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m   3293\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m   3294\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m   3295\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m   3296\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   3297\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:999\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    996\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    997\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[0;32m--> 999\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39;49mfunc_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfunc_kwargs)\n\u001b[1;32m   1001\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1002\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1003\u001b[0m func_outputs \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(convert, func_outputs,\n\u001b[1;32m   1004\u001b[0m                                   expand_composites\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:3687\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3681\u001b[0m \u001b[39m@eager_function\u001b[39m\u001b[39m.\u001b[39mdefun_with_attributes(\n\u001b[1;32m   3682\u001b[0m     input_signature\u001b[39m=\u001b[39mstructure\u001b[39m.\u001b[39mget_flat_tensor_specs(\n\u001b[1;32m   3683\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_structure),\n\u001b[1;32m   3684\u001b[0m     autograph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m   3685\u001b[0m     attributes\u001b[39m=\u001b[39mdefun_kwargs)\n\u001b[1;32m   3686\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_fn\u001b[39m(\u001b[39m*\u001b[39margs):  \u001b[39m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[0;32m-> 3687\u001b[0m   ret \u001b[39m=\u001b[39m wrapper_helper(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m   3688\u001b[0m   ret \u001b[39m=\u001b[39m structure\u001b[39m.\u001b[39mto_tensor_list(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_structure, ret)\n\u001b[1;32m   3689\u001b[0m   \u001b[39mreturn\u001b[39;00m [ops\u001b[39m.\u001b[39mconvert_to_tensor(t) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m ret]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:3617\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3615\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[1;32m   3616\u001b[0m   nested_args \u001b[39m=\u001b[39m (nested_args,)\n\u001b[0;32m-> 3617\u001b[0m ret \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39;49mtf_convert(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func, ag_ctx)(\u001b[39m*\u001b[39;49mnested_args)\n\u001b[1;32m   3618\u001b[0m \u001b[39mif\u001b[39;00m _should_pack(ret):\n\u001b[1;32m   3619\u001b[0m   ret \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(ret)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:692\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    691\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 692\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[1;32m    693\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    694\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:382\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    379\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    381\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 382\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    384\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    386\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    387\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:463\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    460\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    462\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 463\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    464\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/keras/engine/data_adapter.py:1397\u001b[0m, in \u001b[0;36m_make_class_weight_map_fn.<locals>._class_weights_map_fn\u001b[0;34m(*data)\u001b[0m\n\u001b[1;32m   1394\u001b[0m x, y, sw \u001b[39m=\u001b[39m unpack_x_y_sample_weight(data)\n\u001b[1;32m   1396\u001b[0m \u001b[39mif\u001b[39;00m nest\u001b[39m.\u001b[39mis_nested(y):\n\u001b[0;32m-> 1397\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1398\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39m`class_weight` is only supported for Models with a single output.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1400\u001b[0m \u001b[39mif\u001b[39;00m y\u001b[39m.\u001b[39mshape\u001b[39m.\u001b[39mrank \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m   1401\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`class_weight` not supported for \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1402\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m3+ dimensional targets.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: `class_weight` is only supported for Models with a single output."
     ]
    }
   ],
   "source": [
    "from EQTransformer.core.trainer import trainer\n",
    "trainer(input_hdf5='../ModelsAndSampleData/100samples.hdf5',\n",
    "        input_csv='../ModelsAndSampleData/100samples.csv',\n",
    "        output_name='test_trainer',                \n",
    "        cnn_blocks=2,\n",
    "        lstm_blocks=1,\n",
    "        padding='same',\n",
    "        activation='relu',\n",
    "        drop_rate=0.2,\n",
    "        label_type='gaussian',\n",
    "        add_event_r=0.6,\n",
    "        add_gap_r=0.2,\n",
    "        shift_event_r=0.9,\n",
    "        add_noise_r=0.5, \n",
    "        mode='generator',\n",
    "        train_valid_test_split=[0.60, 0.20, 0.20],\n",
    "        batch_size=20,\n",
    "        epochs=10, \n",
    "        patience=2,\n",
    "        gpuid=None,\n",
    "        gpu_limit=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Test Your Model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then test the model you just trained based on the ground truth labels:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/amirreza/Desktop/Desktop/Project/Final Project/EQTransformer/examples/training.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/amirreza/Desktop/Desktop/Project/Final%20Project/EQTransformer/examples/training.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mEQTransformer\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtester\u001b[39;00m \u001b[39mimport\u001b[39;00m tester\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/amirreza/Desktop/Desktop/Project/Final%20Project/EQTransformer/examples/training.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m tester(input_hdf5\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m../ModelsAndSampleData/100samples.hdf5\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/amirreza/Desktop/Desktop/Project/Final%20Project/EQTransformer/examples/training.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m        input_testset\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtest_trainer_outputs/test.npy\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/amirreza/Desktop/Desktop/Project/Final%20Project/EQTransformer/examples/training.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m        input_model\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtest_trainer_outputs/models/test_trainer_001.h5\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/amirreza/Desktop/Desktop/Project/Final%20Project/EQTransformer/examples/training.ipynb#W6sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m        gpuid\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/amirreza/Desktop/Desktop/Project/Final%20Project/EQTransformer/examples/training.ipynb#W6sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m        gpu_limit\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/EQTransformer-0.1.61-py3.9.egg/EQTransformer/__init__.py:7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mEQTransformer\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtrainer\u001b[39;00m \u001b[39mimport\u001b[39;00m trainer \n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mEQTransformer\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtester\u001b[39;00m \u001b[39mimport\u001b[39;00m tester\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mEQTransformer\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpredictor\u001b[39;00m \u001b[39mimport\u001b[39;00m predictor\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/EQTransformer-0.1.61-py3.9.egg/EQTransformer/core/__init__.py:4\u001b[0m\n\u001b[1;32m      2\u001b[0m name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcore\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mEqT_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtrainer\u001b[39;00m \u001b[39mimport\u001b[39;00m trainer\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtester\u001b[39;00m \u001b[39mimport\u001b[39;00m tester\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/EQTransformer-0.1.61-py3.9.egg/EQTransformer/core/EqT_utils.py:17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[1;32m     16\u001b[0m os\u001b[39m.\u001b[39menviron[\u001b[39m'\u001b[39m\u001b[39mKERAS_BACKEND\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtensorflow\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m---> 17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mimport\u001b[39;00m keras\n\u001b[1;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m backend \u001b[39mas\u001b[39;00m K\n\u001b[1;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m add, Activation, LSTM, Conv1D, InputSpec\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/__init__.py:41\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msix\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_six\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_sys\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtools\u001b[39;00m \u001b[39mimport\u001b[39;00m module_util \u001b[39mas\u001b[39;00m _module_util\n\u001b[1;32m     42\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlazy_loader\u001b[39;00m \u001b[39mimport\u001b[39;00m LazyLoader \u001b[39mas\u001b[39;00m _LazyLoader\n\u001b[1;32m     44\u001b[0m \u001b[39m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/__init__.py:40\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtraceback\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[39m# We aim to keep this file minimal and ideally remove completely.\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[39m# If you are adding a new file with @tf_export decorators,\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[39m# import it in modules_with_exports.py instead.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \n\u001b[1;32m     37\u001b[0m \u001b[39m# go/tf-wildcard-import\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[39m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m \u001b[39mimport\u001b[39;00m context\n\u001b[1;32m     41\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m pywrap_tensorflow \u001b[39mas\u001b[39;00m _pywrap_tensorflow\n\u001b[1;32m     43\u001b[0m \u001b[39m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \n\u001b[1;32m     45\u001b[0m \u001b[39m# Bring in subpackages.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/eager/context.py:35\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mprotobuf\u001b[39;00m \u001b[39mimport\u001b[39;00m config_pb2\n\u001b[1;32m     34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mprotobuf\u001b[39;00m \u001b[39mimport\u001b[39;00m rewriter_config_pb2\n\u001b[0;32m---> 35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m pywrap_tfe\n\u001b[1;32m     36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m tf2\n\u001b[1;32m     37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mclient\u001b[39;00m \u001b[39mimport\u001b[39;00m pywrap_tf_session\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/pywrap_tfe.py:28\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m print_function\n\u001b[1;32m     27\u001b[0m \u001b[39m# pylint: disable=invalid-import-order,g-bad-import-order, wildcard-import, unused-import\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m pywrap_tensorflow\n\u001b[1;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_pywrap_tfe\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/pywrap_tensorflow.py:64\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39m# pylint: disable=wildcard-import,g-import-not-at-top,line-too-long,undefined-variable\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_pywrap_tensorflow_internal\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m     65\u001b[0m \u001b[39m# This try catch logic is because there is no bazel equivalent for py_extension.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[39m# Externally in opensource we must enable exceptions to load the shared object\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[39m# by exposing the PyInit symbols with pybind. This error will only be\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[39m# caught internally or if someone changes the name of the target _pywrap_tensorflow_internal.\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \n\u001b[1;32m     70\u001b[0m \u001b[39m# This logic is used in other internal projects using py_extension.\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mModuleNotFoundError\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from EQTransformer.core.tester import tester\n",
    "tester(input_hdf5='../ModelsAndSampleData/100samples.hdf5',\n",
    "       input_testset='test_trainer_outputs/test.npy',\n",
    "       input_model='test_trainer_outputs/models/test_trainer_001.h5',\n",
    "       output_name='test_tester',\n",
    "       detection_threshold=0.20,                \n",
    "       P_threshold=0.1,\n",
    "       S_threshold=0.1, \n",
    "       number_of_plots=3,\n",
    "       estimate_uncertainty=True, \n",
    "       number_of_sampling=2,\n",
    "       input_dimention=(6000, 3),\n",
    "       normalization_mode='std',\n",
    "       mode='generator',\n",
    "       batch_size=10,\n",
    "       gpuid=None,\n",
    "       gpu_limit=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
