{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (II) Detection and Picking\n",
    "This notebook demonstrates the use of EQTransformer for performing the earthquake signal detection and seismic phase (P & S) picking on continuous data. Once you have your seismic data - preferentially in mseed format and in individual subfolders for each station- you can perform the detection/picking using the following options:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option (I) on preprocessed (hdf5) files:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This option is recommended for smaller time periods (a few days to a month). This allows you to test the perfomance and explore the effects of different parameters while the provided hdf5 file makes it easy to access the waveforms.\n",
    "\n",
    "For this option you first need to convert your MiniSeed files for each station into a single hdf5 file and a csv file containting the list of traces in the hdf5 file.\n",
    "\n",
    "You can convert MiniSeed files to a hdf5 file using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ Station SV08 has 0 chunks of data.\n",
      "============ Station B921 has 2 chunks of data.\n",
      " Station SV08 had 0 chuncks of data\n",
      "0 slices were written, 0 were expected.\n",
      "Number of 1-components: 0. Number of 2-components: 0. Number of 3-components: 0.\n",
      "============ Station CA06 has 2 chunks of data.\n",
      "  * CA06 (1) .. 20190901 --> 20190902 .. 3 components .. sampling rate: 100.0\n",
      "  * B921 (1) .. 20190901 --> 20190902 .. 3 components .. sampling rate: 100.0\n",
      "  * B921 (2) .. 20190902 --> 20190903 .. 3 components .. sampling rate: 100.0\n",
      "  * CA06 (2) .. 20190902 --> 20190903 .. 3 components .. sampling rate: 100.0\n",
      " Station B921 had 2 chuncks of data\n",
      "4112 slices were written, 4114.0 were expected.\n",
      "Number of 1-components: 0. Number of 2-components: 0. Number of 3-components: 2.\n",
      "Original samplieng rate: 100.0.\n",
      " Station CA06 had 2 chuncks of data\n",
      "4112 slices were written, 4114.0 were expected.\n",
      "Number of 1-components: 0. Number of 2-components: 0. Number of 3-components: 2.\n",
      "Original samplieng rate: 100.0.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from EQTransformer.utils.hdf5_maker import preprocessor\n",
    "\n",
    "json_basepath = os.path.join(os.getcwd(),\"json/station_list.json\")\n",
    "\n",
    "preprocessor(preproc_dir=\"preproc\",\n",
    "             mseed_dir='downloads_mseeds', \n",
    "             stations_json=json_basepath, \n",
    "             overlap=0.3, \n",
    "             n_processor=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will generate one \"station_name.hdf5\" and one \"station_name.csv\" file for each of your stations and put them into a directory named \"mseed_dir+_hdfs\". Then you need to pass the name of the directory containing your hdf5 & CSV files and a model. You can use relatively low threshold values for the detection and picking since EQTransformer is very robust to false positives. Enabling uncertaintiy estimation, outputing probabilities, or plotting all the detected events will slow down the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================\n",
      "Running EqTransformer  0.1.61\n",
      " *** Loading the model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-25 12:53:43.917539: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Loading is complete!\n",
      "######### There are files for 3 stations in downloads_mseeds_processed_hdfs directory. #########\n",
      "========= Started working on B921, 1 out of 3 ...\n",
      "  0%|                                                                         | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-25 12:53:48.257511: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 9/9 [03:58<00:00, 30.23s/it]\n",
      "\n",
      " *** Finished the prediction in: 0 hours and 4 minutes and 16.88 seconds.\n",
      " *** Detected: 5356 events.\n",
      " *** Wrote the results into --> \" /Users/amirreza/Desktop/Desktop/Project/Final Project/EQTransformer/examples/detections1/B921_outputs \"\n",
      "========= Started working on CA06, 2 out of 3 ...\n",
      "100%|█████████████████████████████████████████████████████████████████| 9/9 [04:17<00:00, 28.56s/it]\n",
      "\n",
      "\n",
      " *** Finished the prediction in: 0 hours and 4 minutes and 20.7 seconds.\n",
      " *** Detected: 5448 events.\n",
      " *** Wrote the results into --> \" /Users/amirreza/Desktop/Desktop/Project/Final Project/EQTransformer/examples/detections1/CA06_outputs \"\n",
      "========= Started working on SV08, 3 out of 3 ...\n",
      "100%|█████████████████████████████████████████████████████████████████| 9/9 [04:20<00:00, 28.97s/it]\n",
      "\n",
      "\n",
      " *** Finished the prediction in: 0 hours and 0 minutes and 0.04 seconds.\n",
      " *** Detected: 0 events.\n",
      " *** Wrote the results into --> \" /Users/amirreza/Desktop/Desktop/Project/Final Project/EQTransformer/examples/detections1/SV08_outputs \"\n",
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from EQTransformer.core.predictor import predictor\n",
    "predictor(input_dir='downloads_mseeds_processed_hdfs',   \n",
    "         input_model='../ModelsAndSampleData/EqT_original_model.h5',\n",
    "         output_dir='detections1',\n",
    "         estimate_uncertainty=False, \n",
    "         output_probabilities=False,\n",
    "         number_of_sampling=5,\n",
    "         loss_weights=[0.02, 0.40, 0.58],          \n",
    "         detection_threshold=0.3,                \n",
    "         P_threshold=0.3,\n",
    "         S_threshold=0.3, \n",
    "         number_of_plots=10,\n",
    "         plot_mode='time',\n",
    "         batch_size=500,\n",
    "         number_of_cpus=4,\n",
    "         keepPS=False,\n",
    "         spLimit=60) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using local MiniSeed files you can generate a station_list.json by supplying an absolute path to a directory containing Miniseed files and a station location dictionary using the stationListFromMseed function like the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Module didn't work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/username/Downloads/EQTransformer/examples/downloads_mseeds'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/amirreza/Desktop/Desktop/Project/Final Project/EQTransformer/examples/detection.ipynb Cell 8\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/amirreza/Desktop/Desktop/Project/Final%20Project/EQTransformer/examples/detection.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m mseed_directory \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/Users/username/Downloads/EQTransformer/examples/downloads_mseeds\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/amirreza/Desktop/Desktop/Project/Final%20Project/EQTransformer/examples/detection.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m station_locations \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mCA06\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m35.59962\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m117.49268\u001b[39m, \u001b[39m796.4\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mCA10\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m35.56736\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m117.667427\u001b[39m, \u001b[39m835.9\u001b[39m]}\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/amirreza/Desktop/Desktop/Project/Final%20Project/EQTransformer/examples/detection.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m stationListFromMseed(mseed_directory, station_locations)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/EQTransformer-0.1.61-py3.9.egg/EQTransformer/utils/hdf5_maker.py:500\u001b[0m, in \u001b[0;36mstationListFromMseed\u001b[0;34m(mseed_directory, station_locations, dir_json)\u001b[0m\n\u001b[1;32m    497\u001b[0m station_list \u001b[39m=\u001b[39m {}\n\u001b[1;32m    499\u001b[0m \u001b[39m# loop through subdirectories of specified directory\u001b[39;00m\n\u001b[0;32m--> 500\u001b[0m \u001b[39mfor\u001b[39;00m subdirectory \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39;49mscandir(mseed_directory):\n\u001b[1;32m    501\u001b[0m     \u001b[39mif\u001b[39;00m subdirectory\u001b[39m.\u001b[39mis_dir():\n\u001b[1;32m    502\u001b[0m         channels \u001b[39m=\u001b[39m []\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/username/Downloads/EQTransformer/examples/downloads_mseeds'"
     ]
    }
   ],
   "source": [
    "from EQTransformer.utils.hdf5_maker import stationListFromMseed\n",
    "\n",
    "mseed_directory = '/Users/username/Downloads/EQTransformer/examples/downloads_mseeds'\n",
    "station_locations = {\"CA06\": [35.59962, -117.49268, 796.4], \"CA10\": [35.56736, -117.667427, 835.9]}\n",
    "stationListFromMseed(mseed_directory, station_locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option (II) directly on downloaded MiniSeed files:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can perform the detection/picking directly on .mseed files. \n",
    "This save both prerpcessing time and the extra space needed for hdf5 file. However, it can be more memory intensive. So it is recommended when mseed fils are one month long or shorter.\n",
    "This option also does not allow you to estimate the uncertainties, write the prediction probabilities, or use the advantages of having hdf5 files which makes it easy to access the raw event waveforms based on detection results.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09-25 13:16 [INFO] [EQTransformer] Running EqTransformer  0.1.61\n",
      "09-25 13:16 [INFO] [EQTransformer] *** Loading the model ...\n",
      "09-25 13:16 [INFO] [EQTransformer] *** Loading is complete!\n",
      "09-25 13:16 [INFO] [EQTransformer] *** /Users/amirreza/Desktop/Desktop/Project/Final Project/EQTransformer/examples/detections2 already exists!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay.\n"
     ]
    }
   ],
   "source": [
    "from EQTransformer.core.mseed_predictor import mseed_predictor\n",
    "mseed_predictor(input_dir='downloads_mseeds',   \n",
    "         input_model='../ModelsAndSampleData/EqT_original_model.h5',\n",
    "         stations_json=json_basepath,\n",
    "         output_dir='detections2',\n",
    "         loss_weights=[0.02, 0.40, 0.58],          \n",
    "         detection_threshold=0.7,                \n",
    "         P_threshold=0.3,\n",
    "         S_threshold=0.3, \n",
    "         number_of_plots=10,\n",
    "         plot_mode='time_frequency',\n",
    "         normalization_mode='std',\n",
    "         batch_size=500,\n",
    "         overlap=0.9,\n",
    "         gpuid=None,\n",
    "         gpu_limit=None) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction outputs for each station will be written in your output directory (i.e. 'detections').\n",
    "\n",
    "'X_report.txt' contains processing info on input parameters used for the detection/picking and final \n",
    "results such as running time, the total number of detected events (these are unique events and duplicated ones have been already removed). \n",
    "\n",
    "'X_prediction_results.csv' contains detection/picking results in the figures folder you can find the plots for the number of events that you specified in the above comment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
